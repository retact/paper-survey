<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>EMG on Paper Survey</title>
    <link>https://ps.retact.net/tags/emg/</link>
    <description>Recent content in EMG on Paper Survey</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja</language>
    <lastBuildDate>Mon, 02 May 2022 12:50:42 +0900</lastBuildDate><atom:link href="https://ps.retact.net/tags/emg/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Deep Learning for Electromyographic Hand Gesture Signal Classification Using Transfer Learning</title>
      <link>https://ps.retact.net/posts/2022-05-02-deep-learning-for-electromyographic-hand-gesture-signal-classification-using-transfer-learning/</link>
      <pubDate>Mon, 02 May 2022 12:50:42 +0900</pubDate>
      
      <guid>https://ps.retact.net/posts/2022-05-02-deep-learning-for-electromyographic-hand-gesture-signal-classification-using-transfer-learning/</guid>
      <description>&lt;h2 id=&#34;1-どんなもの&#34;&gt;1. どんなもの？&lt;/h2&gt;
&lt;p&gt;Tlを用いて，複数のユーザー間から取得されたデータを用いて，簡易的にジェスチャー分類タスクの学習を行う手法を提示している．&lt;br&gt;
タスクとしては2つのデータセットを取得し，Ninaproを合わせた3つのデータベースで,CWT,rawEMG,スペクトログラムのそれぞれ3つの異なる入力のネットワークを用い，その有用性を示している．&lt;br&gt;
また，real-time feedbackをもちいたユースケースにおいて，精度劣化を軽減させることを示している．&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Forearm Motion Discrimination Technique Using Real Time EMG Signals</title>
      <link>https://ps.retact.net/posts/2021-09-08-forearm-motion-discrimination-technique-using-real-time-emg-signals/</link>
      <pubDate>Wed, 08 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ps.retact.net/posts/2021-09-08-forearm-motion-discrimination-technique-using-real-time-emg-signals/</guid>
      <description>&lt;h2 id=&#34;1-どんなもの&#34;&gt;1. どんなもの？&lt;/h2&gt;
&lt;p&gt;300m/s以下のレスポンス速度について&lt;a href=&#34;https://ieeexplore.ieee.org/document/8785894&#34;&gt;Real-time Pattern Recognition for Hand Gesture Based on ANN and Surface EMG&lt;/a&gt;で明記されていた理由として紹介されていたが，本文ではその理由に対するエビデンスは示されていない．&lt;br&gt;
本文ではhyper - spheremodel といったみたことのない特徴を用いており，異常値をrestとみなすアプローチがされている.&lt;br&gt;
また移動平均フィルタのデータ数が増えると遅延量が多くなりレスポンス速度が遅くなるという結果明記がされている．　　&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Real Time Pattern Recognition for Hand Gesture Based on ANN and Surface EMG</title>
      <link>https://ps.retact.net/posts/2021-09-08-real-time-pattern-recognition-for-hand-gesture-based-on-ann-and-surface-emg/</link>
      <pubDate>Wed, 08 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ps.retact.net/posts/2021-09-08-real-time-pattern-recognition-for-hand-gesture-based-on-ann-and-surface-emg/</guid>
      <description>&lt;h2 id=&#34;1-どんなもの&#34;&gt;1. どんなもの？&lt;/h2&gt;
&lt;p&gt;フィードフォワードの3層ANNを用いた5クラスのジェスチャーのリアルタイム分類について記述されている．手法として，スライドウィンドウ法をもちいて，4つの時間的特徴とHjorthParametersを元に特徴量ベクトルを作成し，平均応答速度を300msに押さえ分類精度は96％を示している．またそれぞれの特徴の筋電的な意味についても述べられている．&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Investigation of Different Approaches to Real Time Control of Prosthetic Hands With Electromyography Signals</title>
      <link>https://ps.retact.net/posts/2021-08-30-investigation-of-different-approaches-to-real-time-control-of-prosthetic-hands-with-electromyography-signals/</link>
      <pubDate>Mon, 30 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ps.retact.net/posts/2021-08-30-investigation-of-different-approaches-to-real-time-control-of-prosthetic-hands-with-electromyography-signals/</guid>
      <description>&lt;h2 id=&#34;1-どんなもの&#34;&gt;1. どんなもの？&lt;/h2&gt;
&lt;p&gt;ACCを用いたマルチモーダルによる筋電パターン認識システムの評価と感覚フィードバックの考案をしている．筋電パターン認識では300msで応答するソフトウェアハードウェアシステムを開発しており，従来の分類精度と同等の結果を得られている，またフィードバックシステムにおいても把持する物体の質量が変わっても把持し続けられる結果を得ている．&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Design of Continuous EMG Classification Approaches Towards the Control of a Robotic Exoskeleton in Reaching Movements</title>
      <link>https://ps.retact.net/posts/2021-08-11-design-of-continuous-emg-classification-approaches-towards-the-control-of-a-robotic-exoskeleton-in-reaching-movements/</link>
      <pubDate>Wed, 11 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ps.retact.net/posts/2021-08-11-design-of-continuous-emg-classification-approaches-towards-the-control-of-a-robotic-exoskeleton-in-reaching-movements/</guid>
      <description>&lt;h2 id=&#34;1-どんなもの&#34;&gt;1. どんなもの？&lt;/h2&gt;
&lt;p&gt;実用段階では連続的なオンライン制御が行われていない中，8人の健常者の上腕の筋電図を用いて８種類の動きを分類する擬似オンラインアプリケーションを開発し，その精度を70％以上としている．またこの論文では3つのウィンドウサイズによる分類精度の影響についても述べられている．&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Determining the Optimal Window Length for Pattern Recognition Based Myoelectric Control: Balancing the Competing Effects of Classification Error and Controller Delay</title>
      <link>https://ps.retact.net/posts/2021-07-30-determining-the-optimal-window-length-for-pattern-recognition-based-myoelectric-control-balancing-the-competing-effects-of-classification-error-and-controller-delay/</link>
      <pubDate>Fri, 30 Jul 2021 14:55:35 +0900</pubDate>
      
      <guid>https://ps.retact.net/posts/2021-07-30-determining-the-optimal-window-length-for-pattern-recognition-based-myoelectric-control-balancing-the-competing-effects-of-classification-error-and-controller-delay/</guid>
      <description>&lt;h2 id=&#34;1-どんなもの&#34;&gt;1. どんなもの？&lt;/h2&gt;
&lt;p&gt;筋電図のパターン認識において，分類誤差とコントローラの遅延とリアルタイムの制御性から解析ウィンドウの長さを50ms-550msの中でどの値が最適かを調べている．実験はTarget Achievement Controlによって評価され，ユーザーのパフォーマンスは分類誤差が小さいほど，向上し，遅延量が大きくなるほど低下するトレードオフの関係であることがわかっている．その上でこの研究で用いたシステムでの最適な解析ウィンドウの長さは150-250msであることがわかった．&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>An Online SEMG Motion Classification Framework for Tele Operating the Robotic Hand</title>
      <link>https://ps.retact.net/posts/2021-07-29-an-online-semg-motion-classification-framework-for-tele-operating-the-robotic-hand/</link>
      <pubDate>Thu, 29 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ps.retact.net/posts/2021-07-29-an-online-semg-motion-classification-framework-for-tele-operating-the-robotic-hand/</guid>
      <description>&lt;h2 id=&#34;1-どんなもの&#34;&gt;1. どんなもの？&lt;/h2&gt;
&lt;p&gt;ロボットハンドを動かすためのオンラインsEMG動作分類のフレームワークを提案している．オフライン学習とオンライン認識フェーズで構成されており，オフラインフェーズでは3つの分類器を比較し，オンラインフェーズでは2つの閾値を用いたデータセグメンテーションが設計されている．5つ分類において73.56%の総合精度を示した．&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>A Preliminary Analysis of Analysis Window Size and Voting Size With a Time Delay for a Robust Real Time SEMG Pattern Recognition</title>
      <link>https://ps.retact.net/posts/2021-07-28-a-preliminary-analysis-of-analysis-window-size-and-voting-size-with-a-time-delay-for-a-robust-real-time-semg-pattern-recognition/</link>
      <pubDate>Wed, 28 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ps.retact.net/posts/2021-07-28-a-preliminary-analysis-of-analysis-window-size-and-voting-size-with-a-time-delay-for-a-robust-real-time-semg-pattern-recognition/</guid>
      <description>&lt;h2 id=&#34;1-どんなもの&#34;&gt;1. どんなもの？&lt;/h2&gt;
&lt;p&gt;動作の開始時と終了時の不安定なEMGにおいて，分類精度と速度はトレードオフの関係であり，信号処理の解析ウィンドウサイズと分類の投票サイズのパラメータから，パターン認識の精度の限界を調べたものである．またGoogleEarthを用いたパイロット試験を通じて解析ウィンドウサイズと投票サイズの有用なガイドラインを提案している．&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Gesture Recognition by Instantaneous Surface EMG Images</title>
      <link>https://ps.retact.net/posts/2021-07-21-gesture-recognition-by-instantaneous-surface-emg-images/</link>
      <pubDate>Wed, 21 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ps.retact.net/posts/2021-07-21-gesture-recognition-by-instantaneous-surface-emg-images/</guid>
      <description>&lt;h2 id=&#34;1-どんなもの&#34;&gt;1. どんなもの？&lt;/h2&gt;
&lt;p&gt;特定の瞬間のHD-sEMGによるジェスチャー認識法.高密度のsEMGから画像データを生成しDeepLearningによって識別する実験をおこなったところ，窓付き特徴量を用いず8つのジェスチャー識別において，89.3%の識別精度が得られ，52個のジェスチャー分類においても先行研究より優れた結果を得られた．&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Artificial Neural Network Classifier in Comparison With LDA and LS SVM Classifiers to Recognize 52 Hand Postures and Movements</title>
      <link>https://ps.retact.net/posts/2021-07-05-artificial-neural-network-classifier-in-comparison-with-lda-and-ls-svm-classifiers-to-recognize-52-hand-postures-and-movements/</link>
      <pubDate>Mon, 05 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ps.retact.net/posts/2021-07-05-artificial-neural-network-classifier-in-comparison-with-lda-and-ls-svm-classifiers-to-recognize-52-hand-postures-and-movements/</guid>
      <description>&lt;h2 id=&#34;1-どんなもの&#34;&gt;1. どんなもの？&lt;/h2&gt;
&lt;p&gt;NINAPRO5のデータを使って，MLPとLDAとLS-SVMの分類器に対してMAV, IAV, RMS, WL, E, ER1, ER2, CCなどと言った時間的特徴を入力し，それぞれの組み合わせの52種類のジェスチャ分類を比較している．全ての特徴を用いてMLPでは96.34%の平均精度，LDAに対してMAVとCCを用いた分類で平均精度84.23%，LS-SVMに対してIAV+MAV+RMS+WLで85.19%の平均精度が算出された．&lt;br&gt;
またE，ER1，ER2のような単一の特徴量を用いた場合，MLPは他の2つの分類器と比較して性能が低下すると言った結果も示している．&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Recursive Multi Signal Temporal Fusions With Attention Mechanism Improves EMG Feature Extraction</title>
      <link>https://ps.retact.net/posts/2021-06-23-recursive-multi-signal-temporal-fusions-with-attention-mechanism-improves-emg-feature-extraction/</link>
      <pubDate>Wed, 23 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ps.retact.net/posts/2021-06-23-recursive-multi-signal-temporal-fusions-with-attention-mechanism-improves-emg-feature-extraction/</guid>
      <description>&lt;h2 id=&#34;1-どんなもの&#34;&gt;1. どんなもの？&lt;/h2&gt;
&lt;p&gt;筋電におけるジェスチャー分類において,WL,ZC,RMSをLSTMでの長期記憶を利用し拡張し空間的特徴にするRMTF(Recursive Multi-Signal Temporal Fusion)特徴抽出法の提案で，&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>A 3D Printed, Adjustable Armband for Electromyography Based Finger Movement Classification With Haptic Feedback</title>
      <link>https://ps.retact.net/posts/2021-06-21-a-3d-printed-adjustable-armband-for-electromyography-based-finger-movement-classification-with-haptic-feedback/</link>
      <pubDate>Mon, 21 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ps.retact.net/posts/2021-06-21-a-3d-printed-adjustable-armband-for-electromyography-based-finger-movement-classification-with-haptic-feedback/</guid>
      <description>&lt;h2 id=&#34;1-どんなもの&#34;&gt;1. どんなもの？&lt;/h2&gt;
&lt;p&gt;1本の指のタッピング動作を検出するために，電極の配置を完全に調整できる3Dプリントされた低コストのアームバンドの提案。9本の指の動きを検出するために，8チャンネルのSEMG信号から抽出した特徴量を用いて機械学習を行い、500msウィンドウの特徴量を用いたKNNでは71%、200msのきれいなデータのサブセットから抽出した特徴量を用いたKNNでは93%の精度を記録した。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Building the Ninapro Database: A Resource for the Biorobotics Community</title>
      <link>https://ps.retact.net/posts/2021-06-20-building-the-ninapro-database-a-resource-for-the-biorobotics-community/</link>
      <pubDate>Sun, 20 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ps.retact.net/posts/2021-06-20-building-the-ninapro-database-a-resource-for-the-biorobotics-community/</guid>
      <description>&lt;h2 id=&#34;1-どんなもの&#34;&gt;1. どんなもの？&lt;/h2&gt;
&lt;p&gt;筋電図のデータセットで、ASCIIフォーマットで27人の健常者の52のジェスチャーの運動データのsEMGデータが含まれており、数年に渡って100人以上の健常者と50人以上の切断者のデータが追加されることが計画されているため、撮影設定，実験プロトコル,データの保存形式などが示されている。またこのデータベースに対してLeast-Squares SVMによる分類評価も行っている。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>A Low-Cost, Wireless, 3-D-Printed Custom Armband for sEMG Hand Gesture Recognition</title>
      <link>https://ps.retact.net/posts/2021-06-15-a-low-cost-wireless-3-d-printed-custom-armband-for-semg-hand-gesture-recognition/</link>
      <pubDate>Wed, 16 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ps.retact.net/posts/2021-06-15-a-low-cost-wireless-3-d-printed-custom-armband-for-semg-hand-gesture-recognition/</guid>
      <description>&lt;h2 id=&#34;1-どんなもの&#34;&gt;1. どんなもの？&lt;/h2&gt;
&lt;p&gt;1000Hzのサンプリングレートで10チャンネルの計測能力を持ち、60gで製作費が150ドルの安価なEMGアームバンドの提案。市販されているMyoアームバンドとLDA(Hudins&#39; Time-Domain Featureset)による分類性能と生データ周波数データによってアームバンドの性能を比較している。また比較の際には22人の健常者に11のジェスチャーをそれぞれ4セット取得したデータセットを作っている。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Deep Learning for Electromyographic Hand Gesture Signal Classification Using Transfer Learning</title>
      <link>https://ps.retact.net/posts/2021-06-02-deep-learning-for-electromyographic-hand-gesture-signal-classification-using-transfer-learning/</link>
      <pubDate>Wed, 02 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ps.retact.net/posts/2021-06-02-deep-learning-for-electromyographic-hand-gesture-signal-classification-using-transfer-learning/</guid>
      <description>&lt;h2 id=&#34;1-どんなもの&#34;&gt;1. どんなもの？&lt;/h2&gt;
&lt;p&gt;転移学習を利用し、推定精度を向上させる手法の提案。深層学習に用いる2つのデータセットは19人,17人の健常者から取得し、NinaProDB5
を活用しており、それぞれに対してraw EMG, spectrograms,continuous wavelet transform (CWT)を用いたネットワークを構築し推定精度を比較したところ、
CWTベースのConvNetでは17人の参加者の7つのジェスチャーに対して98.31％、生のEMGベースのConvNetでは10人の参加者の18のジェスチャーに対して68.98％のオフライン精度を達成している。
またこの論文ではConvNetの性能を体系的かつ大幅に向上させる新しい転移学習スキームを紹介している。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>An Investigation of Temporally Inspired Time Domain Features for Electromyographic Pattern Recognition</title>
      <link>https://ps.retact.net/posts/2021-05-22-an-investigation-of-temporally-inspired-time-domain-features-for-electromyographic-pattern-recognition/</link>
      <pubDate>Sat, 22 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ps.retact.net/posts/2021-05-22-an-investigation-of-temporally-inspired-time-domain-features-for-electromyographic-pattern-recognition/</guid>
      <description>&lt;h2 id=&#34;1-どんなもの&#34;&gt;1. どんなもの？&lt;/h2&gt;
&lt;p&gt;ピーク検出から導出された時間的な新しい特徴量について2つ紹介しており、この時間的特徴量精度は自己回帰係数，ヒストグラム，ゼロクロスなどといった一般的に用いられる時間的特徴よりも，それぞれ8％，11％，17％優れている分類精度を示している。またHudginsの時間領域の特徴と比較して，ロバストな特徴セットの一部として追加情報を提供することが示されている。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Navigating features: a topologically informed chart of electromyographic features space</title>
      <link>https://ps.retact.net/posts/2021-05-18-navigating-features-a-topologically-informed-chart-of-electromyographic-features-space/</link>
      <pubDate>Tue, 18 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ps.retact.net/posts/2021-05-18-navigating-features-a-topologically-informed-chart-of-electromyographic-features-space/</guid>
      <description>&lt;h2 id=&#34;1-どんなもの&#34;&gt;1. どんなもの？&lt;/h2&gt;
&lt;p&gt;EMGの特徴量58個を３つのデータセットにおいて、トポロジカルな手法を用いてサブグループを探索してこのグループに基づいたクラス分類可能性、ロバスト性、複雑性などについて分類しそれぞれの特徴量抽出の評価について紹介している。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>A Framework for Hand Gesture Recognition Based on Accelerometer and EMG Sensors</title>
      <link>https://ps.retact.net/posts/2021-05-12-a-framework-for-hand-gesture-recognition-based-on-accelerometer-and-emg-sensors/</link>
      <pubDate>Wed, 12 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ps.retact.net/posts/2021-05-12-a-framework-for-hand-gesture-recognition-based-on-accelerometer-and-emg-sensors/</guid>
      <description>&lt;h2 id=&#34;1-どんなもの&#34;&gt;1. どんなもの？&lt;/h2&gt;
&lt;p&gt;ACCとEMGセンサーの融合のために、決定木とマルチストリームHMMを用いたハンドジェスチャー認識のフレームワークの提案で様々な手首や指のジェスチャーの認識精度がこれまでの5〜10％向上した。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>A versatile embedded platform for EMG acquisition and gesture recognition</title>
      <link>https://ps.retact.net/posts/2021-05-09-a-versatile-embedded-platform-for-emg-acquisition-and-gesture-recognition/</link>
      <pubDate>Sun, 09 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ps.retact.net/posts/2021-05-09-a-versatile-embedded-platform-for-emg-acquisition-and-gesture-recognition/</guid>
      <description>&lt;h2 id=&#34;1-どんなもの&#34;&gt;1. どんなもの？&lt;/h2&gt;
&lt;p&gt;ハイエンドなアクティブ筋電精度と同等の精度を示すリアルタイムジェスチャー認識のためのEMG信号の取得と処理が可能で安価なウェアラブルデバイスを開発.　デバイスはCerebroとCoretexが統合されており、SVM認識アルゴリズムを実装し，オフラインでの最先端の結果と同等の90%の精度で29.7 mWの消費電力性能を示している。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Learning Effective Spatial–Temporal Features for sEMG Armband-Based Gesture Recognition</title>
      <link>https://ps.retact.net/posts/2021-04-25-learning-effective-spatialtemporal-features-for-semg-armband-based-gesture-recognition/</link>
      <pubDate>Sun, 25 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ps.retact.net/posts/2021-04-25-learning-effective-spatialtemporal-features-for-semg-armband-based-gesture-recognition/</guid>
      <description>&lt;h2 id=&#34;1-どんなもの&#34;&gt;1. どんなもの？&lt;/h2&gt;
&lt;p&gt;時間的に非定常信号であるsEMGを空間-時間特徴に基づく、ジェスチャー認識法(STF-GR)の提案。非定常多チャンネルのsEMGを分解し、定常副信号に合同変換したのち、空間的独立性と時間的定常性を生み出す。その後負の対数尤度ベースのコスト関数を用いて，最終的なジェスチャーの判定する。STF-GRはsEMGアームバンドのために設計されたもの。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Hand Gesture Recognition Based on Semg Signal and Improved SVM Voting Method</title>
      <link>https://ps.retact.net/posts/2021-04-24-hand-gesture-recognition-based-on-semg-signal-and-improved-svm-voting-method/</link>
      <pubDate>Sat, 24 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ps.retact.net/posts/2021-04-24-hand-gesture-recognition-based-on-semg-signal-and-improved-svm-voting-method/</guid>
      <description>&lt;h2 id=&#34;1-どんなもの&#34;&gt;1. どんなもの？&lt;/h2&gt;
&lt;p&gt;できるだけ少ない特徴量でできるだけ多くのジェスチャーパターンを認識するSVMアルゴリズムの提案。従来のvoting Methodとは異なり全てのサブセットトレーニングに対応している他分離可能性を高めた方法の提案がされている。これにより特徴ベクトル次元数は3元で12のジェスチャーを84%の認識精度で分類している。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Approximate model for interactive-tendon driven mechanism of a multiple-DoFs myoelectric prosthetic hand&#34;</title>
      <link>https://ps.retact.net/posts/2021-04-18-approximate-model-for-interactive-tendon-driven-mechanism-of-a-multiple-dofs-myoelectric-prosthetic-hand/</link>
      <pubDate>Sun, 18 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ps.retact.net/posts/2021-04-18-approximate-model-for-interactive-tendon-driven-mechanism-of-a-multiple-dofs-myoelectric-prosthetic-hand/</guid>
      <description>&lt;h2 id=&#34;1-どんなもの&#34;&gt;1. どんなもの？&lt;/h2&gt;
&lt;p&gt;インタラクティブな腱駆動機構の筋電義手の開発とその評価。形状モデルと関節トルクの平衡モデルに基づいた腱駆動機構の制御方法の近似モデルとキャリブレーションについて。ロボットハンドの角度関係は1次関数で近似ができ、ロボットハンドの関節角度と腱ワイヤーのけん引の長さはSIN関数で近似できるPIP,DIPの角度が小さい場合MPの動きを10%以下の動きで制御可能であり、また近似モデルを用いることでDIP、PIPのの関節の動きを9-15%の誤差で制御でき、インタラクティブな腱駆動機構の義手開発に可能性がある！
　&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>A myoelectric prosthetic hand with muscle synergy–based motion determination and impedance model–based biomimetic control</title>
      <link>https://ps.retact.net/posts/2021-04-17-a-myoelectric-prosthetic-hand-with-muscle-synergybased-motion-determination-and-impedance-modelbased-biomimetic-control/</link>
      <pubDate>Sat, 17 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ps.retact.net/posts/2021-04-17-a-myoelectric-prosthetic-hand-with-muscle-synergybased-motion-determination-and-impedance-modelbased-biomimetic-control/</guid>
      <description>&lt;h2 id=&#34;1-どんなもの&#34;&gt;1. どんなもの？&lt;/h2&gt;
&lt;p&gt;3Dプリンタによって生成可能な義手において、筋シナジーに基づく動作決定法と生体模倣インピーダンス制御を導入することで，
学習されていない複合動作の分類や，スムーズで直感的な義手の指の動きを実現した筋電義手
オープンソースの義手を改造して比較的簡単に設計されている。
また義手の制御自体にはPID制御を用いている。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>2021 09 09 Real Time Hand Gesture Recognition Based on Artificial Feed Forward Neural Networks and EMG</title>
      <link>https://ps.retact.net/posts/2021-09-09-real-time-hand-gesture-recognition-based-on-artificial-feed-forward-neural-networks-and-emg/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ps.retact.net/posts/2021-09-09-real-time-hand-gesture-recognition-based-on-artificial-feed-forward-neural-networks-and-emg/</guid>
      <description>&lt;h2 id=&#34;1-どんなもの&#34;&gt;1. どんなもの？&lt;/h2&gt;
&lt;p&gt;3層ニューラルネットワークで5つのジェスチャーを90.1%の精度でresponse速度11msで分類している．&lt;br&gt;
また，ウィンドウサイズ500点でスライドウィンドウが10点であり，整流化のち5次のバターワースフィルタを用いてエンベロープで平滑化したあとに，筋収縮に対応する点をセグメント化している．特徴量抽出はDTWを利用しており，分類では条件付き確立で0.5の閾値を取らなければrestと判断する手法が取られている．&lt;br&gt;
またこの手法の利点として,トレーニングデータが30個であるため，学習コストが非常に少ないといったことがあげられる．
今後の手法としてRNNを用いた分類モジュールを提案している．&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>
