<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Paper Survey</title>
    <link>https://ps.retact.net/posts/</link>
    <description>Recent content in Posts on Paper Survey</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja</language>
    <lastBuildDate>Sun, 20 Jun 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://ps.retact.net/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Building the Ninapro Database: A Resource for the Biorobotics Community</title>
      <link>https://ps.retact.net/posts/2021-06-20-building-the-ninapro-database-a-resource-for-the-biorobotics-community/</link>
      <pubDate>Sun, 20 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ps.retact.net/posts/2021-06-20-building-the-ninapro-database-a-resource-for-the-biorobotics-community/</guid>
      <description>&lt;h2 id=&#34;1-どんなもの&#34;&gt;1. どんなもの？&lt;/h2&gt;
&lt;p&gt;筋電図のデータセットで、ASCIIフォーマットで27人の健常者の52のジェスチャーの運動データのsEMGデータが含まれており、数年に渡って100人以上の健常者と50人以上の切断者のデータが追加されることが計画されているため、撮影設定，実験プロトコル,データの保存形式などが示されている。またこのデータベースに対してLeast-Squares SVMによる分類評価も行っている。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>A Low-Cost, Wireless, 3-D-Printed Custom Armband for sEMG Hand Gesture Recognition</title>
      <link>https://ps.retact.net/posts/2021-06-15-a-low-cost-wireless-3-d-printed-custom-armband-for-semg-hand-gesture-recognition/</link>
      <pubDate>Wed, 16 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ps.retact.net/posts/2021-06-15-a-low-cost-wireless-3-d-printed-custom-armband-for-semg-hand-gesture-recognition/</guid>
      <description>&lt;h2 id=&#34;1-どんなもの&#34;&gt;1. どんなもの？&lt;/h2&gt;
&lt;p&gt;1000Hzのサンプリングレートで10チャンネルの計測能力を持ち、60gで製作費が150ドルの安価なEMGアームバンドの提案。市販されているMyoアームバンドとLDA(Hudins&#39; Time-Domain Featureset)による分類性能と生データ周波数データによってアームバンドの性能を比較している。また比較の際には22人の健常者に11のジェスチャーをそれぞれ4セット取得したデータセットを作っている。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Deep Learning for Electromyographic Hand Gesture Signal Classification Using Transfer Learning</title>
      <link>https://ps.retact.net/posts/2021-06-02-deep-learning-for-electromyographic-hand-gesture-signal-classification-using-transfer-learning/</link>
      <pubDate>Wed, 02 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ps.retact.net/posts/2021-06-02-deep-learning-for-electromyographic-hand-gesture-signal-classification-using-transfer-learning/</guid>
      <description>&lt;h2 id=&#34;1-どんなもの&#34;&gt;1. どんなもの？&lt;/h2&gt;
&lt;p&gt;転移学習を利用し、推定精度を向上させる手法の提案。深層学習に用いる2つのデータセットは19人,17人の健常者から取得し、NinaProDB5
を活用しており、それぞれに対してraw EMG, spectrograms,continuous wavelet transform (CWT)を用いたネットワークを構築し推定精度を比較したところ、
CWTベースのConvNetでは17人の参加者の7つのジェスチャーに対して98.31％、生のEMGベースのConvNetでは10人の参加者の18のジェスチャーに対して68.98％のオフライン精度を達成している。
またこの論文ではConvNetの性能を体系的かつ大幅に向上させる新しい転移学習スキームを紹介している。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>An Investigation of Temporally Inspired Time Domain Features for Electromyographic Pattern Recognition</title>
      <link>https://ps.retact.net/posts/2021-05-22-an-investigation-of-temporally-inspired-time-domain-features-for-electromyographic-pattern-recognition/</link>
      <pubDate>Sat, 22 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ps.retact.net/posts/2021-05-22-an-investigation-of-temporally-inspired-time-domain-features-for-electromyographic-pattern-recognition/</guid>
      <description>&lt;h2 id=&#34;1-どんなもの&#34;&gt;1. どんなもの？&lt;/h2&gt;
&lt;p&gt;ピーク検出から導出された時間的な新しい特徴量について2つ紹介しており、この時間的特徴量精度は自己回帰係数，ヒストグラム，ゼロクロスなどといった一般的に用いられる時間的特徴よりも，それぞれ8％，11％，17％優れている分類精度を示している。またHudginsの時間領域の特徴と比較して，ロバストな特徴セットの一部として追加情報を提供することが示されている。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Navigating features: a topologically informed chart of electromyographic features space</title>
      <link>https://ps.retact.net/posts/2021-05-18-navigating-features-a-topologically-informed-chart-of-electromyographic-features-space/</link>
      <pubDate>Tue, 18 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ps.retact.net/posts/2021-05-18-navigating-features-a-topologically-informed-chart-of-electromyographic-features-space/</guid>
      <description>&lt;h2 id=&#34;1-どんなもの&#34;&gt;1. どんなもの？&lt;/h2&gt;
&lt;p&gt;EMGの特徴量58個を３つのデータセットにおいて、トポロジカルな手法を用いてサブグループを探索してこのグループに基づいたクラス分類可能性、ロバスト性、複雑性などについて分類しそれぞれの特徴量抽出の評価について紹介している。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>A Framework for Hand Gesture Recognition Based on Accelerometer and EMG Sensors</title>
      <link>https://ps.retact.net/posts/2021-05-12-a-framework-for-hand-gesture-recognition-based-on-accelerometer-and-emg-sensors/</link>
      <pubDate>Wed, 12 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ps.retact.net/posts/2021-05-12-a-framework-for-hand-gesture-recognition-based-on-accelerometer-and-emg-sensors/</guid>
      <description>&lt;h2 id=&#34;1-どんなもの&#34;&gt;1. どんなもの？&lt;/h2&gt;
&lt;p&gt;ACCとEMGセンサーの融合のために、決定木とマルチストリームHMMを用いたハンドジェスチャー認識のフレームワークの提案で様々な手首や指のジェスチャーの認識精度がこれまでの5〜10％向上した。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>A versatile embedded platform for EMG acquisition and gesture recognition</title>
      <link>https://ps.retact.net/posts/2021-05-09-a-versatile-embedded-platform-for-emg-acquisition-and-gesture-recognition/</link>
      <pubDate>Sun, 09 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ps.retact.net/posts/2021-05-09-a-versatile-embedded-platform-for-emg-acquisition-and-gesture-recognition/</guid>
      <description>&lt;h2 id=&#34;1-どんなもの&#34;&gt;1. どんなもの？&lt;/h2&gt;
&lt;p&gt;ハイエンドなアクティブ筋電精度と同等の精度を示すリアルタイムジェスチャー認識のためのEMG信号の取得と処理が可能で安価なウェアラブルデバイスを開発.　デバイスはCerebroとCoretexが統合されており、SVM認識アルゴリズムを実装し，オフラインでの最先端の結果と同等の90%の精度で29.7 mWの消費電力性能を示している。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Learning Effective Spatial–Temporal Features for sEMG Armband-Based Gesture Recognition</title>
      <link>https://ps.retact.net/posts/2021-04-25-learning-effective-spatialtemporal-features-for-semg-armband-based-gesture-recognition/</link>
      <pubDate>Sun, 25 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ps.retact.net/posts/2021-04-25-learning-effective-spatialtemporal-features-for-semg-armband-based-gesture-recognition/</guid>
      <description>&lt;h2 id=&#34;1-どんなもの&#34;&gt;1. どんなもの？&lt;/h2&gt;
&lt;p&gt;時間的に非定常信号であるsEMGを空間-時間特徴に基づく、ジェスチャー認識法(STF-GR)の提案。非定常多チャンネルのsEMGを分解し、定常副信号に合同変換したのち、空間的独立性と時間的定常性を生み出す。その後負の対数尤度ベースのコスト関数を用いて，最終的なジェスチャーの判定する。STF-GRはsEMGアームバンドのために設計されたもの。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Hand Gesture Recognition Based on Semg Signal and Improved SVM Voting Method</title>
      <link>https://ps.retact.net/posts/2021-04-24-hand-gesture-recognition-based-on-semg-signal-and-improved-svm-voting-method/</link>
      <pubDate>Sat, 24 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ps.retact.net/posts/2021-04-24-hand-gesture-recognition-based-on-semg-signal-and-improved-svm-voting-method/</guid>
      <description>&lt;h2 id=&#34;1-どんなもの&#34;&gt;1. どんなもの？&lt;/h2&gt;
&lt;p&gt;できるだけ少ない特徴量でできるだけ多くのジェスチャーパターンを認識するSVMアルゴリズムの提案。従来のvoting Methodとは異なり全てのサブセットトレーニングに対応している他分離可能性を高めた方法の提案がされている。これにより特徴ベクトル次元数は3元で12のジェスチャーを84%の認識精度で分類している。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Approximate model for interactive-tendon driven mechanism of a multiple-DoFs myoelectric prosthetic hand&#34;</title>
      <link>https://ps.retact.net/posts/2021-04-18-approximate-model-for-interactive-tendon-driven-mechanism-of-a-multiple-dofs-myoelectric-prosthetic-hand/</link>
      <pubDate>Sun, 18 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ps.retact.net/posts/2021-04-18-approximate-model-for-interactive-tendon-driven-mechanism-of-a-multiple-dofs-myoelectric-prosthetic-hand/</guid>
      <description>&lt;h2 id=&#34;1-どんなもの&#34;&gt;1. どんなもの？&lt;/h2&gt;
&lt;p&gt;インタラクティブな腱駆動機構の筋電義手の開発とその評価。形状モデルと関節トルクの平衡モデルに基づいた腱駆動機構の制御方法の近似モデルとキャリブレーションについて。ロボットハンドの角度関係は1次関数で近似ができ、ロボットハンドの関節角度と腱ワイヤーのけん引の長さはSIN関数で近似できるPIP,DIPの角度が小さい場合MPの動きを10%以下の動きで制御可能であり、また近似モデルを用いることでDIP、PIPのの関節の動きを9-15%の誤差で制御でき、インタラクティブな腱駆動機構の義手開発に可能性がある！
　&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>A myoelectric prosthetic hand with muscle synergy–based motion determination and impedance model–based biomimetic control</title>
      <link>https://ps.retact.net/posts/2021-04-17-a-myoelectric-prosthetic-hand-with-muscle-synergybased-motion-determination-and-impedance-modelbased-biomimetic-control/</link>
      <pubDate>Sat, 17 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ps.retact.net/posts/2021-04-17-a-myoelectric-prosthetic-hand-with-muscle-synergybased-motion-determination-and-impedance-modelbased-biomimetic-control/</guid>
      <description>&lt;h2 id=&#34;1-どんなもの&#34;&gt;1. どんなもの？&lt;/h2&gt;
&lt;p&gt;3Dプリンタによって生成可能な義手において、筋シナジーに基づく動作決定法と生体模倣インピーダンス制御を導入することで，
学習されていない複合動作の分類や，スムーズで直感的な義手の指の動きを実現した筋電義手
オープンソースの義手を改造して比較的簡単に設計されている。
また義手の制御自体にはPID制御を用いている。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>A Soft-Robotic Approach to Anthropomorphic Robotic Hand Dexterity</title>
      <link>https://ps.retact.net/posts/2021-04-17-a-soft-robotic-approach-to-anthropomorphic-robotic-hand-dexterity/</link>
      <pubDate>Sat, 17 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ps.retact.net/posts/2021-04-17-a-soft-robotic-approach-to-anthropomorphic-robotic-hand-dexterity/</guid>
      <description>&lt;h2 id=&#34;1-どんなもの&#34;&gt;1. どんなもの？&lt;/h2&gt;
&lt;p&gt;ソフトロボットハンドBCL-26ではGRASP分類法や親指の器用さにおいて機能的な器用さを実現し、すべての指の独立制御を可能にした。
フレキシブルケーブル、弾性リンクなどを用いて実現した受動的なしなやかさ（パッシブコンプライアンス）を導入することによって本来機械的に要求される要件を大幅き軽減することができ、
指の可動域が大幅に上昇した。26自由度のロボットハンドについて性能検証した。ただし、ソフトアクチュエータにおけるスピードについては限界がある。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Development of five-finger multi-DoF myoelectric hands with a power allocation mechanism</title>
      <link>https://ps.retact.net/posts/2021-04-16-development-of-five-finger-multi-dof-myoelectric-hands-with-a-power-allocation-mechanism/</link>
      <pubDate>Fri, 16 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ps.retact.net/posts/2021-04-16-development-of-five-finger-multi-dof-myoelectric-hands-with-a-power-allocation-mechanism/</guid>
      <description>&lt;h2 id=&#34;1-どんなもの&#34;&gt;1. どんなもの？&lt;/h2&gt;
&lt;p&gt;ロボットハンドのピンチ動作の冗長な自由度を利用した握力を向上させるPower allocation mechanismによって、
指先の力がこれを用いていないものと比べて64%上昇させることができ、3本指で1kgの物体を持ち上げた。
サイズや重量を大幅に変えることなく、自由度が高く安定した状態で握力を向上できる。&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>
