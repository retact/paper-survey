<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Paper Survey</title>
    <link>https://ps.retact.net/</link>
    <description>Recent content on Paper Survey</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja</language>
    <lastBuildDate>Fri, 30 Jul 2021 14:55:35 +0900</lastBuildDate><atom:link href="https://ps.retact.net/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Determining the Optimal Window Length for Pattern Recognition Based Myoelectric Control: Balancing the Competing Effects of Classification Error and Controller Delay</title>
      <link>https://ps.retact.net/posts/2021-07-30-determining-the-optimal-window-length-for-pattern-recognition-based-myoelectric-control-balancing-the-competing-effects-of-classification-error-and-controller-delay/</link>
      <pubDate>Fri, 30 Jul 2021 14:55:35 +0900</pubDate>
      
      <guid>https://ps.retact.net/posts/2021-07-30-determining-the-optimal-window-length-for-pattern-recognition-based-myoelectric-control-balancing-the-competing-effects-of-classification-error-and-controller-delay/</guid>
      <description>&lt;h2 id=&#34;1-どんなもの&#34;&gt;1. どんなもの？&lt;/h2&gt;
&lt;p&gt;筋電図のパターン認識において，分類誤差とコントローラの遅延とリアルタイムの制御性から解析ウィンドウの長さを50ms-550msの中でどの値が最適かを調べている．実験はTarget Achievement Controlによって評価され，ユーザーのパフォーマンスは分類誤差が小さいほど，向上し，遅延量が大きくなるほど低下するトレードオフの関係であることがわかっている．その上でこの研究で用いたシステムでの最適な解析ウィンドウの長さは150-250msであることがわかった．&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>An Online SEMG Motion Classification Framework for Tele Operating the Robotic Hand</title>
      <link>https://ps.retact.net/posts/2021-07-29-an-online-semg-motion-classification-framework-for-tele-operating-the-robotic-hand/</link>
      <pubDate>Thu, 29 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ps.retact.net/posts/2021-07-29-an-online-semg-motion-classification-framework-for-tele-operating-the-robotic-hand/</guid>
      <description>&lt;h2 id=&#34;1-どんなもの&#34;&gt;1. どんなもの？&lt;/h2&gt;
&lt;p&gt;ロボットハンドを動かすためのオンラインsEMG動作分類のフレームワークを提案している．オフライン学習とオンライン認識フェーズで構成されており，オフラインフェーズでは3つの分類器を比較し，オンラインフェーズでは2つの閾値を用いたデータセグメンテーションが設計されている．5つ分類において73.56%の総合精度を示した．&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>A Preliminary Analysis of Analysis Window Size and Voting Size With a Time Delay for a Robust Real Time SEMG Pattern Recognition</title>
      <link>https://ps.retact.net/posts/2021-07-28-a-preliminary-analysis-of-analysis-window-size-and-voting-size-with-a-time-delay-for-a-robust-real-time-semg-pattern-recognition/</link>
      <pubDate>Wed, 28 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ps.retact.net/posts/2021-07-28-a-preliminary-analysis-of-analysis-window-size-and-voting-size-with-a-time-delay-for-a-robust-real-time-semg-pattern-recognition/</guid>
      <description>&lt;h2 id=&#34;1-どんなもの&#34;&gt;1. どんなもの？&lt;/h2&gt;
&lt;p&gt;動作の開始時と終了時の不安定なEMGにおいて，分類精度と速度はトレードオフの関係であり，信号処理の解析ウィンドウサイズと分類の投票サイズのパラメータから，パターン認識の精度の限界を調べたものである．またGoogleEarthを用いたパイロット試験を通じて解析ウィンドウサイズと投票サイズの有用なガイドラインを提案している．&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Gesture Recognition by Instantaneous Surface EMG Images</title>
      <link>https://ps.retact.net/posts/2021-07-21-gesture-recognition-by-instantaneous-surface-emg-images/</link>
      <pubDate>Wed, 21 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ps.retact.net/posts/2021-07-21-gesture-recognition-by-instantaneous-surface-emg-images/</guid>
      <description>&lt;h2 id=&#34;1-どんなもの&#34;&gt;1. どんなもの？&lt;/h2&gt;
&lt;p&gt;特定の瞬間のHD-sEMGによるジェスチャー認識法.高密度のsEMGから画像データを生成しDeepLearningによって識別する実験をおこなったところ，窓付き特徴量を用いず8つのジェスチャー識別において，89.3%の識別精度が得られ，52個のジェスチャー分類においても先行研究より優れた結果を得られた．&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Artificial Neural Network Classifier in Comparison With LDA and LS SVM Classifiers to Recognize 52 Hand Postures and Movements</title>
      <link>https://ps.retact.net/posts/2021-07-05-artificial-neural-network-classifier-in-comparison-with-lda-and-ls-svm-classifiers-to-recognize-52-hand-postures-and-movements/</link>
      <pubDate>Mon, 05 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ps.retact.net/posts/2021-07-05-artificial-neural-network-classifier-in-comparison-with-lda-and-ls-svm-classifiers-to-recognize-52-hand-postures-and-movements/</guid>
      <description>&lt;h2 id=&#34;1-どんなもの&#34;&gt;1. どんなもの？&lt;/h2&gt;
&lt;p&gt;NINAPRO5のデータを使って，MLPとLDAとLS-SVMの分類器に対してMAV, IAV, RMS, WL, E, ER1, ER2, CCなどと言った時間的特徴を入力し，それぞれの組み合わせの52種類のジェスチャ分類を比較している．全ての特徴を用いてMLPでは96.34%の平均精度，LDAに対してMAVとCCを用いた分類で平均精度84.23%，LS-SVMに対してIAV+MAV+RMS+WLで85.19%の平均精度が算出された．&lt;br&gt;
またE，ER1，ER2のような単一の特徴量を用いた場合，MLPは他の2つの分類器と比較して性能が低下すると言った結果も示している．&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>A 3D Printed, Adjustable Armband for Electromyography Based Finger Movement Classification With Haptic Feedback</title>
      <link>https://ps.retact.net/posts/2021-06-21-a-3d-printed-adjustable-armband-for-electromyography-based-finger-movement-classification-with-haptic-feedback/</link>
      <pubDate>Mon, 21 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ps.retact.net/posts/2021-06-21-a-3d-printed-adjustable-armband-for-electromyography-based-finger-movement-classification-with-haptic-feedback/</guid>
      <description>&lt;h2 id=&#34;1-どんなもの&#34;&gt;1. どんなもの？&lt;/h2&gt;
&lt;p&gt;1本の指のタッピング動作を検出するために，電極の配置を完全に調整できる3Dプリントされた低コストのアームバンドの提案。9本の指の動きを検出するために，8チャンネルのSEMG信号から抽出した特徴量を用いて機械学習を行い、500msウィンドウの特徴量を用いたKNNでは71%、200msのきれいなデータのサブセットから抽出した特徴量を用いたKNNでは93%の精度を記録した。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Building the Ninapro Database: A Resource for the Biorobotics Community</title>
      <link>https://ps.retact.net/posts/2021-06-20-building-the-ninapro-database-a-resource-for-the-biorobotics-community/</link>
      <pubDate>Sun, 20 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ps.retact.net/posts/2021-06-20-building-the-ninapro-database-a-resource-for-the-biorobotics-community/</guid>
      <description>&lt;h2 id=&#34;1-どんなもの&#34;&gt;1. どんなもの？&lt;/h2&gt;
&lt;p&gt;筋電図のデータセットで、ASCIIフォーマットで27人の健常者の52のジェスチャーの運動データのsEMGデータが含まれており、数年に渡って100人以上の健常者と50人以上の切断者のデータが追加されることが計画されているため、撮影設定，実験プロトコル,データの保存形式などが示されている。またこのデータベースに対してLeast-Squares SVMによる分類評価も行っている。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>A Low-Cost, Wireless, 3-D-Printed Custom Armband for sEMG Hand Gesture Recognition</title>
      <link>https://ps.retact.net/posts/2021-06-15-a-low-cost-wireless-3-d-printed-custom-armband-for-semg-hand-gesture-recognition/</link>
      <pubDate>Wed, 16 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ps.retact.net/posts/2021-06-15-a-low-cost-wireless-3-d-printed-custom-armband-for-semg-hand-gesture-recognition/</guid>
      <description>&lt;h2 id=&#34;1-どんなもの&#34;&gt;1. どんなもの？&lt;/h2&gt;
&lt;p&gt;1000Hzのサンプリングレートで10チャンネルの計測能力を持ち、60gで製作費が150ドルの安価なEMGアームバンドの提案。市販されているMyoアームバンドとLDA(Hudins&#39; Time-Domain Featureset)による分類性能と生データ周波数データによってアームバンドの性能を比較している。また比較の際には22人の健常者に11のジェスチャーをそれぞれ4セット取得したデータセットを作っている。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title></title>
      <link>https://ps.retact.net/archives/</link>
      <pubDate>Fri, 11 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ps.retact.net/archives/</guid>
      <description></description>
    </item>
    
    <item>
      <title>About</title>
      <link>https://ps.retact.net/about/</link>
      <pubDate>Fri, 11 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ps.retact.net/about/</guid>
      <description>&lt;h1 id=&#34;paper-survey&#34;&gt;Paper Survey&lt;/h1&gt;
&lt;h2 id=&#34;rules&#34;&gt;Rules&lt;/h2&gt;
&lt;p&gt;○ Submit the paper you intend to read to issues.&lt;br&gt;
○ Summarize the papers you read according to the following format.&lt;/p&gt;
&lt;h2 id=&#34;format&#34;&gt;Format&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;</description>
    </item>
    
    <item>
      <title>Deep Learning for Electromyographic Hand Gesture Signal Classification Using Transfer Learning</title>
      <link>https://ps.retact.net/posts/2021-06-02-deep-learning-for-electromyographic-hand-gesture-signal-classification-using-transfer-learning/</link>
      <pubDate>Wed, 02 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ps.retact.net/posts/2021-06-02-deep-learning-for-electromyographic-hand-gesture-signal-classification-using-transfer-learning/</guid>
      <description>&lt;h2 id=&#34;1-どんなもの&#34;&gt;1. どんなもの？&lt;/h2&gt;
&lt;p&gt;転移学習を利用し、推定精度を向上させる手法の提案。深層学習に用いる2つのデータセットは19人,17人の健常者から取得し、NinaProDB5
を活用しており、それぞれに対してraw EMG, spectrograms,continuous wavelet transform (CWT)を用いたネットワークを構築し推定精度を比較したところ、
CWTベースのConvNetでは17人の参加者の7つのジェスチャーに対して98.31％、生のEMGベースのConvNetでは10人の参加者の18のジェスチャーに対して68.98％のオフライン精度を達成している。
またこの論文ではConvNetの性能を体系的かつ大幅に向上させる新しい転移学習スキームを紹介している。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>An Investigation of Temporally Inspired Time Domain Features for Electromyographic Pattern Recognition</title>
      <link>https://ps.retact.net/posts/2021-05-22-an-investigation-of-temporally-inspired-time-domain-features-for-electromyographic-pattern-recognition/</link>
      <pubDate>Sat, 22 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ps.retact.net/posts/2021-05-22-an-investigation-of-temporally-inspired-time-domain-features-for-electromyographic-pattern-recognition/</guid>
      <description>&lt;h2 id=&#34;1-どんなもの&#34;&gt;1. どんなもの？&lt;/h2&gt;
&lt;p&gt;ピーク検出から導出された時間的な新しい特徴量について2つ紹介しており、この時間的特徴量精度は自己回帰係数，ヒストグラム，ゼロクロスなどといった一般的に用いられる時間的特徴よりも，それぞれ8％，11％，17％優れている分類精度を示している。またHudginsの時間領域の特徴と比較して，ロバストな特徴セットの一部として追加情報を提供することが示されている。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Navigating features: a topologically informed chart of electromyographic features space</title>
      <link>https://ps.retact.net/posts/2021-05-18-navigating-features-a-topologically-informed-chart-of-electromyographic-features-space/</link>
      <pubDate>Tue, 18 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ps.retact.net/posts/2021-05-18-navigating-features-a-topologically-informed-chart-of-electromyographic-features-space/</guid>
      <description>&lt;h2 id=&#34;1-どんなもの&#34;&gt;1. どんなもの？&lt;/h2&gt;
&lt;p&gt;EMGの特徴量58個を３つのデータセットにおいて、トポロジカルな手法を用いてサブグループを探索してこのグループに基づいたクラス分類可能性、ロバスト性、複雑性などについて分類しそれぞれの特徴量抽出の評価について紹介している。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>A Framework for Hand Gesture Recognition Based on Accelerometer and EMG Sensors</title>
      <link>https://ps.retact.net/posts/2021-05-12-a-framework-for-hand-gesture-recognition-based-on-accelerometer-and-emg-sensors/</link>
      <pubDate>Wed, 12 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ps.retact.net/posts/2021-05-12-a-framework-for-hand-gesture-recognition-based-on-accelerometer-and-emg-sensors/</guid>
      <description>&lt;h2 id=&#34;1-どんなもの&#34;&gt;1. どんなもの？&lt;/h2&gt;
&lt;p&gt;ACCとEMGセンサーの融合のために、決定木とマルチストリームHMMを用いたハンドジェスチャー認識のフレームワークの提案で様々な手首や指のジェスチャーの認識精度がこれまでの5〜10％向上した。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>A versatile embedded platform for EMG acquisition and gesture recognition</title>
      <link>https://ps.retact.net/posts/2021-05-09-a-versatile-embedded-platform-for-emg-acquisition-and-gesture-recognition/</link>
      <pubDate>Sun, 09 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ps.retact.net/posts/2021-05-09-a-versatile-embedded-platform-for-emg-acquisition-and-gesture-recognition/</guid>
      <description>&lt;h2 id=&#34;1-どんなもの&#34;&gt;1. どんなもの？&lt;/h2&gt;
&lt;p&gt;ハイエンドなアクティブ筋電精度と同等の精度を示すリアルタイムジェスチャー認識のためのEMG信号の取得と処理が可能で安価なウェアラブルデバイスを開発.　デバイスはCerebroとCoretexが統合されており、SVM認識アルゴリズムを実装し，オフラインでの最先端の結果と同等の90%の精度で29.7 mWの消費電力性能を示している。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Learning Effective Spatial–Temporal Features for sEMG Armband-Based Gesture Recognition</title>
      <link>https://ps.retact.net/posts/2021-04-25-learning-effective-spatialtemporal-features-for-semg-armband-based-gesture-recognition/</link>
      <pubDate>Sun, 25 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ps.retact.net/posts/2021-04-25-learning-effective-spatialtemporal-features-for-semg-armband-based-gesture-recognition/</guid>
      <description>&lt;h2 id=&#34;1-どんなもの&#34;&gt;1. どんなもの？&lt;/h2&gt;
&lt;p&gt;時間的に非定常信号であるsEMGを空間-時間特徴に基づく、ジェスチャー認識法(STF-GR)の提案。非定常多チャンネルのsEMGを分解し、定常副信号に合同変換したのち、空間的独立性と時間的定常性を生み出す。その後負の対数尤度ベースのコスト関数を用いて，最終的なジェスチャーの判定する。STF-GRはsEMGアームバンドのために設計されたもの。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Hand Gesture Recognition Based on Semg Signal and Improved SVM Voting Method</title>
      <link>https://ps.retact.net/posts/2021-04-24-hand-gesture-recognition-based-on-semg-signal-and-improved-svm-voting-method/</link>
      <pubDate>Sat, 24 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ps.retact.net/posts/2021-04-24-hand-gesture-recognition-based-on-semg-signal-and-improved-svm-voting-method/</guid>
      <description>&lt;h2 id=&#34;1-どんなもの&#34;&gt;1. どんなもの？&lt;/h2&gt;
&lt;p&gt;できるだけ少ない特徴量でできるだけ多くのジェスチャーパターンを認識するSVMアルゴリズムの提案。従来のvoting Methodとは異なり全てのサブセットトレーニングに対応している他分離可能性を高めた方法の提案がされている。これにより特徴ベクトル次元数は3元で12のジェスチャーを84%の認識精度で分類している。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Approximate model for interactive-tendon driven mechanism of a multiple-DoFs myoelectric prosthetic hand&#34;</title>
      <link>https://ps.retact.net/posts/2021-04-18-approximate-model-for-interactive-tendon-driven-mechanism-of-a-multiple-dofs-myoelectric-prosthetic-hand/</link>
      <pubDate>Sun, 18 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ps.retact.net/posts/2021-04-18-approximate-model-for-interactive-tendon-driven-mechanism-of-a-multiple-dofs-myoelectric-prosthetic-hand/</guid>
      <description>&lt;h2 id=&#34;1-どんなもの&#34;&gt;1. どんなもの？&lt;/h2&gt;
&lt;p&gt;インタラクティブな腱駆動機構の筋電義手の開発とその評価。形状モデルと関節トルクの平衡モデルに基づいた腱駆動機構の制御方法の近似モデルとキャリブレーションについて。ロボットハンドの角度関係は1次関数で近似ができ、ロボットハンドの関節角度と腱ワイヤーのけん引の長さはSIN関数で近似できるPIP,DIPの角度が小さい場合MPの動きを10%以下の動きで制御可能であり、また近似モデルを用いることでDIP、PIPのの関節の動きを9-15%の誤差で制御でき、インタラクティブな腱駆動機構の義手開発に可能性がある！
　&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>A myoelectric prosthetic hand with muscle synergy–based motion determination and impedance model–based biomimetic control</title>
      <link>https://ps.retact.net/posts/2021-04-17-a-myoelectric-prosthetic-hand-with-muscle-synergybased-motion-determination-and-impedance-modelbased-biomimetic-control/</link>
      <pubDate>Sat, 17 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ps.retact.net/posts/2021-04-17-a-myoelectric-prosthetic-hand-with-muscle-synergybased-motion-determination-and-impedance-modelbased-biomimetic-control/</guid>
      <description>&lt;h2 id=&#34;1-どんなもの&#34;&gt;1. どんなもの？&lt;/h2&gt;
&lt;p&gt;3Dプリンタによって生成可能な義手において、筋シナジーに基づく動作決定法と生体模倣インピーダンス制御を導入することで，
学習されていない複合動作の分類や，スムーズで直感的な義手の指の動きを実現した筋電義手
オープンソースの義手を改造して比較的簡単に設計されている。
また義手の制御自体にはPID制御を用いている。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>A Soft-Robotic Approach to Anthropomorphic Robotic Hand Dexterity</title>
      <link>https://ps.retact.net/posts/2021-04-17-a-soft-robotic-approach-to-anthropomorphic-robotic-hand-dexterity/</link>
      <pubDate>Sat, 17 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ps.retact.net/posts/2021-04-17-a-soft-robotic-approach-to-anthropomorphic-robotic-hand-dexterity/</guid>
      <description>&lt;h2 id=&#34;1-どんなもの&#34;&gt;1. どんなもの？&lt;/h2&gt;
&lt;p&gt;ソフトロボットハンドBCL-26ではGRASP分類法や親指の器用さにおいて機能的な器用さを実現し、すべての指の独立制御を可能にした。
フレキシブルケーブル、弾性リンクなどを用いて実現した受動的なしなやかさ（パッシブコンプライアンス）を導入することによって本来機械的に要求される要件を大幅き軽減することができ、
指の可動域が大幅に上昇した。26自由度のロボットハンドについて性能検証した。ただし、ソフトアクチュエータにおけるスピードについては限界がある。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Development of five-finger multi-DoF myoelectric hands with a power allocation mechanism</title>
      <link>https://ps.retact.net/posts/2021-04-16-development-of-five-finger-multi-dof-myoelectric-hands-with-a-power-allocation-mechanism/</link>
      <pubDate>Fri, 16 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ps.retact.net/posts/2021-04-16-development-of-five-finger-multi-dof-myoelectric-hands-with-a-power-allocation-mechanism/</guid>
      <description>&lt;h2 id=&#34;1-どんなもの&#34;&gt;1. どんなもの？&lt;/h2&gt;
&lt;p&gt;ロボットハンドのピンチ動作の冗長な自由度を利用した握力を向上させるPower allocation mechanismによって、
指先の力がこれを用いていないものと比べて64%上昇させることができ、3本指で1kgの物体を持ち上げた。
サイズや重量を大幅に変えることなく、自由度が高く安定した状態で握力を向上できる。&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>
